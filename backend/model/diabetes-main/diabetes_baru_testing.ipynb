{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('E:\\\\syntax code\\\\python\\jupytr\\\\neural network\\\\diabetes\\\\diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AgeRange'] = pd.cut(\n",
    "    df['Age'], \n",
    "    bins=[0, 25, 30, 35, 40, 45, 50, 60, float('inf')], \n",
    "    labels=[1, 2, 3, 4, 5, 6, 7, 8]  # Label sebagai integer\n",
    ")\n",
    "\n",
    "# Konversi ke integer jika tidak otomatis\n",
    "df['AgeRange'] = df['AgeRange'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>AgeRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  AgeRange  \n",
       "0                       0.627   50        1         6  \n",
       "1                       0.351   31        0         3  \n",
       "2                       0.672   32        1         3  \n",
       "3                       0.167   21        0         1  \n",
       "4                       2.288   33        1         3  \n",
       "..                        ...  ...      ...       ...  \n",
       "763                     0.171   63        0         8  \n",
       "764                     0.340   27        0         2  \n",
       "765                     0.245   30        0         2  \n",
       "766                     0.349   47        1         6  \n",
       "767                     0.315   23        0         1  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>AgeRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Outcome  AgeRange  \n",
       "0                     0.627        1         6  \n",
       "1                     0.351        0         3  \n",
       "2                     0.672        1         3  \n",
       "3                     0.167        0         1  \n",
       "4                     2.288        1         3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(columns=\"Age\",axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Outcome  Age  \n",
       "0                       0.627        1    6  \n",
       "1                       0.351        0    3  \n",
       "2                       0.672        1    3  \n",
       "3                       0.167        0    1  \n",
       "4                       2.288        1    3  \n",
       "..                        ...      ...  ...  \n",
       "763                     0.171        0    8  \n",
       "764                     0.340        0    2  \n",
       "765                     0.245        0    2  \n",
       "766                     0.349        1    6  \n",
       "767                     0.315        0    1  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'AgeRange':'Age'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome']\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(  data=df['Age'])\n",
    "plt.title('Bar Chart - Distribusi Umur')\n",
    "plt.xlabel('Umur')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BloodPressure'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_describe=df.describe()\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = pd.DataFrame(data_describe, index=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'])\n",
    "\n",
    "# Membuat dokumen Word baru\n",
    "doc = Document()\n",
    "\n",
    "# Menambahkan tabel ke dalam dokumen Word\n",
    "doc.add_table(rows=len(df_describe) + 1, cols=len(df_describe.columns), style='Table Grid')\n",
    "table = doc.tables[0]\n",
    "\n",
    "# Menambahkan header tabel\n",
    "for col_num, column_name in enumerate(df_describe.columns):\n",
    "    table.cell(0, col_num).text = column_name\n",
    "\n",
    "# Menambahkan data ke dalam tabel\n",
    "for row_num, row_data in enumerate(df_describe.itertuples(index=True, name=None)):\n",
    "    row_cells = table.rows[row_num + 1].cells\n",
    "    for col_num, cell_value in enumerate(row_data[1:]):\n",
    "        row_cells[col_num].text = str(cell_value)\n",
    "\n",
    "# Simpan dokumen Word\n",
    "doc.save('data_describe.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns='Outcome',axis=1)\n",
    "y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 19ms/step - loss: 0.6904 - accuracy: 0.6336 - val_loss: 0.6868 - val_accuracy: 0.6494\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.6515 - val_loss: 0.6779 - val_accuracy: 0.6494\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6515 - val_loss: 0.6584 - val_accuracy: 0.6494\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6515 - val_loss: 0.6142 - val_accuracy: 0.6494\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6515 - val_loss: 0.5667 - val_accuracy: 0.6494\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.6515 - val_loss: 0.5490 - val_accuracy: 0.6494\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.6515 - val_loss: 0.5339 - val_accuracy: 0.6494\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.6580 - val_loss: 0.5231 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7573 - val_loss: 0.5167 - val_accuracy: 0.7403\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7638 - val_loss: 0.5130 - val_accuracy: 0.7208\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7704 - val_loss: 0.5032 - val_accuracy: 0.7468\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7850 - val_loss: 0.5005 - val_accuracy: 0.7338\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7704 - val_loss: 0.5027 - val_accuracy: 0.7403\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7785 - val_loss: 0.5007 - val_accuracy: 0.7403\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7785 - val_loss: 0.4985 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7850 - val_loss: 0.5000 - val_accuracy: 0.7338\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7834 - val_loss: 0.4991 - val_accuracy: 0.7468\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7403\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4646 - accuracy: 0.7834 - val_loss: 0.4972 - val_accuracy: 0.7403\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7818 - val_loss: 0.4956 - val_accuracy: 0.7273\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7883 - val_loss: 0.4901 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7866 - val_loss: 0.4923 - val_accuracy: 0.7208\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7818 - val_loss: 0.4933 - val_accuracy: 0.7208\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7915 - val_loss: 0.4952 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7948 - val_loss: 0.4942 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7850 - val_loss: 0.4901 - val_accuracy: 0.7338\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7948 - val_loss: 0.4892 - val_accuracy: 0.7338\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7883 - val_loss: 0.4947 - val_accuracy: 0.7338\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7948 - val_loss: 0.4980 - val_accuracy: 0.7208\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7932 - val_loss: 0.4983 - val_accuracy: 0.7338\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7883 - val_loss: 0.4995 - val_accuracy: 0.7338\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7866 - val_loss: 0.4981 - val_accuracy: 0.7338\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7948 - val_loss: 0.5000 - val_accuracy: 0.7338\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8013 - val_loss: 0.4987 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7980 - val_loss: 0.4979 - val_accuracy: 0.7208\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7883 - val_loss: 0.4973 - val_accuracy: 0.7273\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7866 - val_loss: 0.4997 - val_accuracy: 0.7338\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7883 - val_loss: 0.5000 - val_accuracy: 0.7338\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7915 - val_loss: 0.5005 - val_accuracy: 0.7338\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7818 - val_loss: 0.4977 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7964 - val_loss: 0.4949 - val_accuracy: 0.7208\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7801 - val_loss: 0.4966 - val_accuracy: 0.7338\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4588 - accuracy: 0.7850 - val_loss: 0.4969 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7866 - val_loss: 0.4940 - val_accuracy: 0.7338\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7948 - val_loss: 0.4944 - val_accuracy: 0.7338\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7883 - val_loss: 0.4939 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7850 - val_loss: 0.4934 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7997 - val_loss: 0.4912 - val_accuracy: 0.7338\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7403\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7883 - val_loss: 0.4915 - val_accuracy: 0.7338\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7785 - val_loss: 0.4943 - val_accuracy: 0.7338\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7948 - val_loss: 0.4927 - val_accuracy: 0.7208\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7866 - val_loss: 0.4931 - val_accuracy: 0.7338\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7883 - val_loss: 0.4916 - val_accuracy: 0.7338\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7801 - val_loss: 0.4914 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7850 - val_loss: 0.4924 - val_accuracy: 0.7208\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7866 - val_loss: 0.4913 - val_accuracy: 0.7338\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8013 - val_loss: 0.4915 - val_accuracy: 0.7338\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.7948 - val_loss: 0.4913 - val_accuracy: 0.7338\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7948 - val_loss: 0.4896 - val_accuracy: 0.7338\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7866 - val_loss: 0.4897 - val_accuracy: 0.7403\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7948 - val_loss: 0.4901 - val_accuracy: 0.7403\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7785 - val_loss: 0.4896 - val_accuracy: 0.7338\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7801 - val_loss: 0.4890 - val_accuracy: 0.7338\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7980 - val_loss: 0.4895 - val_accuracy: 0.7403\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7883 - val_loss: 0.4907 - val_accuracy: 0.7403\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7948 - val_loss: 0.4880 - val_accuracy: 0.7468\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7997 - val_loss: 0.4865 - val_accuracy: 0.7403\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7980 - val_loss: 0.4895 - val_accuracy: 0.7403\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4909 - val_accuracy: 0.7468\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8029 - val_loss: 0.4906 - val_accuracy: 0.7468\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7932 - val_loss: 0.4883 - val_accuracy: 0.7468\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7915 - val_loss: 0.4877 - val_accuracy: 0.7468\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7801 - val_loss: 0.4886 - val_accuracy: 0.7468\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7932 - val_loss: 0.4876 - val_accuracy: 0.7532\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7883 - val_loss: 0.4869 - val_accuracy: 0.7532\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7948 - val_loss: 0.4916 - val_accuracy: 0.7468\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7915 - val_loss: 0.4889 - val_accuracy: 0.7403\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7532\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7403\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7834 - val_loss: 0.4878 - val_accuracy: 0.7403\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7532\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.8013 - val_loss: 0.4906 - val_accuracy: 0.7468\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4553 - accuracy: 0.7752 - val_loss: 0.4933 - val_accuracy: 0.7468\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7915 - val_loss: 0.4924 - val_accuracy: 0.7403\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7948 - val_loss: 0.4920 - val_accuracy: 0.7403\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7883 - val_loss: 0.4945 - val_accuracy: 0.7403\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7980 - val_loss: 0.4944 - val_accuracy: 0.7403\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4924 - val_accuracy: 0.7403\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7866 - val_loss: 0.4923 - val_accuracy: 0.7468\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7964 - val_loss: 0.4928 - val_accuracy: 0.7403\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7866 - val_loss: 0.4938 - val_accuracy: 0.7338\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7948 - val_loss: 0.4978 - val_accuracy: 0.7403\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7403\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7948 - val_loss: 0.4973 - val_accuracy: 0.7403\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7915 - val_loss: 0.4970 - val_accuracy: 0.7468\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7964 - val_loss: 0.4969 - val_accuracy: 0.7468\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7801 - val_loss: 0.4990 - val_accuracy: 0.7468\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7948 - val_loss: 0.4961 - val_accuracy: 0.7468\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7948 - val_loss: 0.4970 - val_accuracy: 0.7468\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7468\n",
      "Test Accuracy: 0.75\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Accuracy Score: 0.7467532467532467\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       100\n",
      "           1       0.67      0.56      0.61        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Konversi label menjadi one-hot encoded\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Model initialization\n",
    "classifier = Sequential()\n",
    "\n",
    "# Input layer\n",
    "classifier.add(Dense(units=8, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "classifier.add(Dropout(0.1))  # Dropout setelah input layer\n",
    "\n",
    "# Hidden layers\n",
    "classifier.add(Dense(units=30, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(units=10, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "classifier.add(Dense(units=2, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = classifier.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = classifier.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = classifier.predict(X_test)\n",
    "y_pred = (y_pred_prob[:, 1] > 0.5).astype(int)  # Menggunakan probabilitas kelas 1\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test.argmax(axis=1), y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test.argmax(axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('diabetes_ANN_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 25ms/step - loss: 1.1477 - accuracy: 0.5179 - val_loss: 1.0174 - val_accuracy: 0.6558\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0281 - accuracy: 0.6384 - val_loss: 0.9459 - val_accuracy: 0.6883\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0006 - accuracy: 0.6368 - val_loss: 0.8879 - val_accuracy: 0.7208\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.9261 - accuracy: 0.6726 - val_loss: 0.8462 - val_accuracy: 0.7468\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.8712 - accuracy: 0.6857 - val_loss: 0.8070 - val_accuracy: 0.7208\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.6889 - val_loss: 0.7729 - val_accuracy: 0.7078\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.8304 - accuracy: 0.7264 - val_loss: 0.7455 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7659 - accuracy: 0.7166 - val_loss: 0.7206 - val_accuracy: 0.7078\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.7117 - val_loss: 0.6987 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7231 - val_loss: 0.6801 - val_accuracy: 0.7208\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.7313 - val_loss: 0.6647 - val_accuracy: 0.7208\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.7020 - val_loss: 0.6524 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.7378 - val_loss: 0.6372 - val_accuracy: 0.7208\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.7459 - val_loss: 0.6277 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.7410 - val_loss: 0.6190 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.7606 - val_loss: 0.6082 - val_accuracy: 0.7078\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7427 - val_loss: 0.5969 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.7492 - val_loss: 0.5894 - val_accuracy: 0.7078\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.7378 - val_loss: 0.5835 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6030 - accuracy: 0.7524 - val_loss: 0.5801 - val_accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7785 - val_loss: 0.5748 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7622 - val_loss: 0.5718 - val_accuracy: 0.7078\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7280 - val_loss: 0.5683 - val_accuracy: 0.7208\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7704 - val_loss: 0.5635 - val_accuracy: 0.7078\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7720 - val_loss: 0.5596 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7459 - val_loss: 0.5559 - val_accuracy: 0.7208\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7410 - val_loss: 0.5509 - val_accuracy: 0.7208\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7638 - val_loss: 0.5503 - val_accuracy: 0.7208\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7655 - val_loss: 0.5489 - val_accuracy: 0.7078\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7818 - val_loss: 0.5443 - val_accuracy: 0.7143\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7476 - val_loss: 0.5391 - val_accuracy: 0.7143\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7850 - val_loss: 0.5350 - val_accuracy: 0.7338\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7769 - val_loss: 0.5344 - val_accuracy: 0.7078\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7492 - val_loss: 0.5311 - val_accuracy: 0.7208\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7769 - val_loss: 0.5304 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7785 - val_loss: 0.5313 - val_accuracy: 0.7208\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7671 - val_loss: 0.5317 - val_accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7834 - val_loss: 0.5341 - val_accuracy: 0.7208\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7687 - val_loss: 0.5287 - val_accuracy: 0.7338\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.8013 - val_loss: 0.5262 - val_accuracy: 0.7208\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7704 - val_loss: 0.5248 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7752 - val_loss: 0.5223 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7834 - val_loss: 0.5202 - val_accuracy: 0.7403\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7720 - val_loss: 0.5194 - val_accuracy: 0.7403\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7687 - val_loss: 0.5209 - val_accuracy: 0.7078\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7541 - val_loss: 0.5158 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7932 - val_loss: 0.5159 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7736 - val_loss: 0.5243 - val_accuracy: 0.7078\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7704 - val_loss: 0.5222 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7655 - val_loss: 0.5246 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7769 - val_loss: 0.5192 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7818 - val_loss: 0.5171 - val_accuracy: 0.7208\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7834 - val_loss: 0.5156 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7834 - val_loss: 0.5157 - val_accuracy: 0.7208\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7866 - val_loss: 0.5163 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7720 - val_loss: 0.5180 - val_accuracy: 0.7208\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7720 - val_loss: 0.5148 - val_accuracy: 0.7078\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7801 - val_loss: 0.5142 - val_accuracy: 0.7078\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7606 - val_loss: 0.5140 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7785 - val_loss: 0.5168 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7736 - val_loss: 0.5163 - val_accuracy: 0.7208\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7752 - val_loss: 0.5180 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7850 - val_loss: 0.5154 - val_accuracy: 0.7208\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7915 - val_loss: 0.5174 - val_accuracy: 0.7078\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7883 - val_loss: 0.5172 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7915 - val_loss: 0.5166 - val_accuracy: 0.7143\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7785 - val_loss: 0.5174 - val_accuracy: 0.7208\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7915 - val_loss: 0.5190 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7883 - val_loss: 0.5158 - val_accuracy: 0.7338\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7866 - val_loss: 0.5180 - val_accuracy: 0.7208\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7752 - val_loss: 0.5187 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7883 - val_loss: 0.5154 - val_accuracy: 0.7208\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4750 - accuracy: 0.7964 - val_loss: 0.5136 - val_accuracy: 0.7078\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7687 - val_loss: 0.5137 - val_accuracy: 0.7208\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7850 - val_loss: 0.5135 - val_accuracy: 0.7208\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7638 - val_loss: 0.5112 - val_accuracy: 0.7078\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7704 - val_loss: 0.5120 - val_accuracy: 0.7143\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7850 - val_loss: 0.5125 - val_accuracy: 0.7208\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7818 - val_loss: 0.5124 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7801 - val_loss: 0.5124 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7915 - val_loss: 0.5183 - val_accuracy: 0.7078\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7834 - val_loss: 0.5219 - val_accuracy: 0.7078\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7883 - val_loss: 0.5169 - val_accuracy: 0.7078\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7801 - val_loss: 0.5141 - val_accuracy: 0.7208\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7932 - val_loss: 0.5185 - val_accuracy: 0.7143\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7899 - val_loss: 0.5179 - val_accuracy: 0.7078\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7915 - val_loss: 0.5170 - val_accuracy: 0.7143\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7752 - val_loss: 0.5199 - val_accuracy: 0.7338\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7785 - val_loss: 0.5178 - val_accuracy: 0.7078\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7013\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7850 - val_loss: 0.5172 - val_accuracy: 0.7013\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7997 - val_loss: 0.5186 - val_accuracy: 0.7208\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7948 - val_loss: 0.5238 - val_accuracy: 0.7208\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7915 - val_loss: 0.5232 - val_accuracy: 0.7208\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7671 - val_loss: 0.5232 - val_accuracy: 0.7143\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7208\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7866 - val_loss: 0.5340 - val_accuracy: 0.7143\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8062 - val_loss: 0.5409 - val_accuracy: 0.7208\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7834 - val_loss: 0.5314 - val_accuracy: 0.7338\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7338\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Accuracy score: 0.7337662337662337\n",
      "MSE: 0.2662337662337662\n",
      "R2 score: -0.1692592694164099\n",
      "F1 Score: 0.7331844237967827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.73      0.73       154\n",
      "         1.0       0.73      0.73      0.73       154\n",
      "\n",
      "    accuracy                           0.73       308\n",
      "   macro avg       0.73      0.73      0.73       308\n",
      "weighted avg       0.73      0.73      0.73       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf \n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Normalisasi data\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# Membuat model Artificial Neural Network (ANN) dengan perubahan\n",
    "model_ann = Sequential([\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=72, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model dengan optimizer RMSprop dan learning rate yang mungkin perlu disesuaikan\n",
    "model_ann.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "finalann = model_ann.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#model_ann.save('diabetes_ANN.h5')\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_ann.evaluate(X_test, y_test)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_prob = model_ann.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "\n",
    "\n",
    "\n",
    "# Pastikan y_test dan y_pred adalah array satu dimensi\n",
    "y_test_single_dim = y_test.ravel()\n",
    "y_pred_single_dim = y_pred_binary.ravel()\n",
    "# Menampilkan classification report\n",
    "print(classification_report(y_test_single_dim, y_pred_single_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.save('diabetes_range_age.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsitektur model dan bobot berhasil disimpan ke file JSON\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Asumsikan Anda memiliki instance model 'model_ann'\n",
    "\n",
    "# Serialize arsitektur model ke dalam format JSON\n",
    "model_json = model_ann.to_json()\n",
    "\n",
    "# Simpan arsitektur model ke dalam file\n",
    "with open('model_architecture.json', 'w') as outfile:\n",
    "    outfile.write(model_json)\n",
    "\n",
    "# Serialize bobot model ke dalam format JSON\n",
    "model_weights = model_ann.get_weights()\n",
    "weights_json = [weight.tolist() for weight in model_weights]\n",
    "\n",
    "# Simpan bobot model ke dalam file\n",
    "with open('model_weights.json', 'w') as outfile:\n",
    "    json.dump(weights_json, outfile)\n",
    "\n",
    "print(\"Arsitektur model dan bobot berhasil disimpan ke file JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11521 (45.00 KB)\n",
      "Trainable params: 11521 (45.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ...\n",
    "\n",
    "# Memuat model yang telah disimpan\n",
    "loaded_model = load_model('E:\\\\syntax code\\\\python\\\\jupytr\\\\neural network\\\\diabetes\\\\diabetes_ANN.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_pred_prob = loaded_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "import seaborn as sns\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = le.fit_transform(y_test)\n",
    "y_pred_encoded = le.transform(y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12048\\746453499.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Membuat prediksi dengan model yang dimuat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0my_pred_prob_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my_pred_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred_prob_loaded\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ...\n",
    "\n",
    "# Memuat model yang telah disimpan\n",
    "loaded_model = load_model('E:\\\\syntax code\\\\python\\\\jupytr\\\\neural network\\\\diabetes\\\\diabetes_ANN.h5')\n",
    "\n",
    "# Membuat prediksi dengan model yang dimuat\n",
    "y_pred_prob_loaded = loaded_model.predict(X_test_scaled)\n",
    "y_pred_loaded = (y_pred_prob_loaded > 0.5).astype(int)\n",
    "\n",
    "# Now you can use y_pred_loaded for evaluation metrics\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "mse_loaded = mean_squared_error(y_test, y_pred_loaded)\n",
    "r2_loaded = r2_score(y_test, y_pred_loaded)\n",
    "f1_loaded = f1_score(y_test, y_pred_loaded, average='weighted')\n",
    "\n",
    "print(\"Accuracy score (loaded model): {}\".format(accuracy_loaded))\n",
    "print(\"MSE (loaded model): {}\".format(mse_loaded))\n",
    "print(\"R2 score (loaded model): {}\".format(r2_loaded))\n",
    "print(\"F1 Score (loaded model): {}\".format(f1_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\n\\nwith open('diabetes_ANN.pkl', 'wb') as file:\\n    pickle.dump(model_ann, file)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "\n",
    "with open('diabetes_ANN.pkl', 'wb') as file:\n",
    "    pickle.dump(model_ann, file)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kompleks model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\n\\nwith open('diabetes_kompleks.sav', 'wb') as file:\\n    pickle.dump(complex_model, file)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "\n",
    "with open('diabetes_kompleks.sav', 'wb') as file:\n",
    "    pickle.dump(complex_model, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "menggunakan model CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 114ms/step - loss: 0.7516 - accuracy: 0.3746 - val_loss: 0.7009 - val_accuracy: 0.4416\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6994 - accuracy: 0.5098 - val_loss: 0.6694 - val_accuracy: 0.6494\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6658 - accuracy: 0.6580 - val_loss: 0.6477 - val_accuracy: 0.6948\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6378 - accuracy: 0.7020 - val_loss: 0.6290 - val_accuracy: 0.7013\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6200 - accuracy: 0.7231 - val_loss: 0.6113 - val_accuracy: 0.7013\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5937 - accuracy: 0.7345 - val_loss: 0.5929 - val_accuracy: 0.7143\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5669 - accuracy: 0.7541 - val_loss: 0.5752 - val_accuracy: 0.7273\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5516 - accuracy: 0.7329 - val_loss: 0.5595 - val_accuracy: 0.7338\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5371 - accuracy: 0.7492 - val_loss: 0.5476 - val_accuracy: 0.7273\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5146 - accuracy: 0.7443 - val_loss: 0.5395 - val_accuracy: 0.7273\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5040 - accuracy: 0.7590 - val_loss: 0.5337 - val_accuracy: 0.7338\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4808 - accuracy: 0.7736 - val_loss: 0.5310 - val_accuracy: 0.7403\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4777 - accuracy: 0.7883 - val_loss: 0.5324 - val_accuracy: 0.7273\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4796 - accuracy: 0.7818 - val_loss: 0.5327 - val_accuracy: 0.7208\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4728 - accuracy: 0.7704 - val_loss: 0.5333 - val_accuracy: 0.7403\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4670 - accuracy: 0.7769 - val_loss: 0.5349 - val_accuracy: 0.7662\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4611 - accuracy: 0.7915 - val_loss: 0.5367 - val_accuracy: 0.7597\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4581 - accuracy: 0.7834 - val_loss: 0.5386 - val_accuracy: 0.7532\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7818 - val_loss: 0.5402 - val_accuracy: 0.7597\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4571 - accuracy: 0.7704 - val_loss: 0.5415 - val_accuracy: 0.7532\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4470 - accuracy: 0.7866 - val_loss: 0.5425 - val_accuracy: 0.7532\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4461 - accuracy: 0.7883 - val_loss: 0.5415 - val_accuracy: 0.7597\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4377 - accuracy: 0.8029 - val_loss: 0.5406 - val_accuracy: 0.7597\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4298 - accuracy: 0.8029 - val_loss: 0.5402 - val_accuracy: 0.7597\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4306 - accuracy: 0.8111 - val_loss: 0.5415 - val_accuracy: 0.7597\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.7948 - val_loss: 0.5435 - val_accuracy: 0.7597\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4304 - accuracy: 0.8013 - val_loss: 0.5450 - val_accuracy: 0.7597\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4249 - accuracy: 0.8046 - val_loss: 0.5461 - val_accuracy: 0.7597\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.8062 - val_loss: 0.5461 - val_accuracy: 0.7597\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7597\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4244 - accuracy: 0.7866 - val_loss: 0.5452 - val_accuracy: 0.7597\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4306 - accuracy: 0.8013 - val_loss: 0.5462 - val_accuracy: 0.7597\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4281 - accuracy: 0.7883 - val_loss: 0.5465 - val_accuracy: 0.7597\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4172 - accuracy: 0.7915 - val_loss: 0.5470 - val_accuracy: 0.7532\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4183 - accuracy: 0.8013 - val_loss: 0.5469 - val_accuracy: 0.7532\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4337 - accuracy: 0.8013 - val_loss: 0.5464 - val_accuracy: 0.7468\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4256 - accuracy: 0.7948 - val_loss: 0.5452 - val_accuracy: 0.7532\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4120 - accuracy: 0.8094 - val_loss: 0.5450 - val_accuracy: 0.7468\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4225 - accuracy: 0.7964 - val_loss: 0.5448 - val_accuracy: 0.7532\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4141 - accuracy: 0.8013 - val_loss: 0.5424 - val_accuracy: 0.7597\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4231 - accuracy: 0.7964 - val_loss: 0.5430 - val_accuracy: 0.7532\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4110 - accuracy: 0.8111 - val_loss: 0.5448 - val_accuracy: 0.7532\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4050 - accuracy: 0.8029 - val_loss: 0.5451 - val_accuracy: 0.7532\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4057 - accuracy: 0.8143 - val_loss: 0.5473 - val_accuracy: 0.7532\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4064 - accuracy: 0.8192 - val_loss: 0.5512 - val_accuracy: 0.7468\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3996 - accuracy: 0.8013 - val_loss: 0.5545 - val_accuracy: 0.7532\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.8046 - val_loss: 0.5577 - val_accuracy: 0.7532\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3997 - accuracy: 0.8111 - val_loss: 0.5615 - val_accuracy: 0.7597\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4059 - accuracy: 0.8078 - val_loss: 0.5644 - val_accuracy: 0.7597\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3959 - accuracy: 0.8127 - val_loss: 0.5644 - val_accuracy: 0.7662\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7662\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Accuracy score: 0.7662337422370911\n",
      "MSE: 0.23376623376623376\n",
      "R2 score: -0.01818181818181852\n",
      "F1 Score: 0.7652380952380953\n",
      "\n",
      "Confusion Matrix:\n",
      "[[82 17]\n",
      " [19 36]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        99\n",
      "           1       0.68      0.65      0.67        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.74      0.74       154\n",
      "weighted avg       0.76      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, recall_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat model Neural Network\n",
    "model_nn = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Kompilasi model\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model_nn.fit(X_train, y_train, epochs=50, batch_size=256, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model_nn.evaluate(X_test, y_test)\n",
    "#model_nn.save('diabetes_CNN.h5')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_pred_prob = model_nn.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert to one-hot encoded if needed\n",
    "# y_pred_one_hot = to_categorical(y_pred, num_classes=num_classes)\n",
    "\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # You can change the average parameter as needed\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.save('diabetes_ANN_range_usia_terbaru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_pred_prob = model_nn.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "import seaborn as sns\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = le.fit_transform(y_test)\n",
    "y_pred_encoded = le.transform(y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 78ms/step - loss: 0.6875 - accuracy: 0.5684 - val_loss: 0.6701 - val_accuracy: 0.6688\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6671 - accuracy: 0.6857 - val_loss: 0.6521 - val_accuracy: 0.6753\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6477 - accuracy: 0.7150 - val_loss: 0.6354 - val_accuracy: 0.6948\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6294 - accuracy: 0.7215 - val_loss: 0.6196 - val_accuracy: 0.7208\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.7231 - val_loss: 0.6046 - val_accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5949 - accuracy: 0.7313 - val_loss: 0.5903 - val_accuracy: 0.7208\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5786 - accuracy: 0.7378 - val_loss: 0.5772 - val_accuracy: 0.7143\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7410 - val_loss: 0.5650 - val_accuracy: 0.7013\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5487 - accuracy: 0.7394 - val_loss: 0.5540 - val_accuracy: 0.7273\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.7476 - val_loss: 0.5442 - val_accuracy: 0.7403\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 616, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_1' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_1' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15240\\3585844613.py\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test Loss: {loss:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test Accuracy: {accuracy:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 616, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_1' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_1' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca dataset\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengubah dimensi data untuk LSTM\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Membuat model LSTM dengan optimizator Adam\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Kompilasi model dengan optimizator Adam\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model_lstm.fit(X_train_lstm, y_train, epochs=10, batch_size=64, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "loss, accuracy = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
