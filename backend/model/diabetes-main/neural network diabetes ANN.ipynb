{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('E:\\syntax code\\python\\jupytr\\dataset\\diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Under-Sampling\n",
      "0    268\n",
      "1    268\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_0,count_1=df.Outcome.value_counts()\n",
    "df_0=df[df['Outcome'] == 0]\n",
    "df_1=df[df['Outcome'] == 1]\n",
    "df_under_0=df_0.sample(count_1)\n",
    "df_test_under=pd.concat([df_under_0,df_1],axis=0)\n",
    "\n",
    "print('Random Under-Sampling')\n",
    "print(df_test_under.Outcome.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.255</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.525</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.687</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "95             6      144             72             27      228  33.9   \n",
       "513            2       91             62              0        0  27.3   \n",
       "456            1      135             54              0        0  26.7   \n",
       "20             3      126             88             41      235  39.3   \n",
       "163            2      100             64             23        0  29.7   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "755            1      128             88             39      110  36.5   \n",
       "757            0      123             72              0        0  36.3   \n",
       "759            6      190             92              0        0  35.5   \n",
       "761            9      170             74             31        0  44.0   \n",
       "766            1      126             60              0        0  30.1   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "95                      0.255   40        0  \n",
       "513                     0.525   22        0  \n",
       "456                     0.687   62        0  \n",
       "20                      0.704   27        0  \n",
       "163                     0.368   21        0  \n",
       "..                        ...  ...      ...  \n",
       "755                     1.057   37        1  \n",
       "757                     0.258   52        1  \n",
       "759                     0.278   66        1  \n",
       "761                     0.403   43        1  \n",
       "766                     0.349   47        1  \n",
       "\n",
       "[536 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop(columns='Outcome',axis=1)\n",
    "y=df_test_under['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ANN FIXXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 26ms/step - loss: 1.1965 - accuracy: 0.5304 - val_loss: 1.0673 - val_accuracy: 0.6389\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1202 - accuracy: 0.5280 - val_loss: 1.0016 - val_accuracy: 0.7407\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0972 - accuracy: 0.5444 - val_loss: 0.9557 - val_accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.5327 - val_loss: 0.9192 - val_accuracy: 0.7870\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.9973 - accuracy: 0.6168 - val_loss: 0.8857 - val_accuracy: 0.7963\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9884 - accuracy: 0.6262 - val_loss: 0.8522 - val_accuracy: 0.8519\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.9620 - accuracy: 0.6168 - val_loss: 0.8250 - val_accuracy: 0.8426\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9349 - accuracy: 0.6308 - val_loss: 0.8026 - val_accuracy: 0.8241\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9075 - accuracy: 0.6028 - val_loss: 0.7732 - val_accuracy: 0.8148\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9102 - accuracy: 0.6215 - val_loss: 0.7465 - val_accuracy: 0.8241\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.8585 - accuracy: 0.6682 - val_loss: 0.7262 - val_accuracy: 0.8426\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8556 - accuracy: 0.6589 - val_loss: 0.7099 - val_accuracy: 0.8519\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8503 - accuracy: 0.6542 - val_loss: 0.6925 - val_accuracy: 0.8426\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8295 - accuracy: 0.6659 - val_loss: 0.6835 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7944 - accuracy: 0.6636 - val_loss: 0.6713 - val_accuracy: 0.8519\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.6612 - val_loss: 0.6579 - val_accuracy: 0.8704\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7972 - accuracy: 0.6636 - val_loss: 0.6420 - val_accuracy: 0.8611\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.6822 - val_loss: 0.6212 - val_accuracy: 0.8611\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6822 - val_loss: 0.6129 - val_accuracy: 0.8426\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7746 - accuracy: 0.6869 - val_loss: 0.6016 - val_accuracy: 0.8426\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.6706 - val_loss: 0.5939 - val_accuracy: 0.8241\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.6963 - val_loss: 0.5823 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.6986 - val_loss: 0.5692 - val_accuracy: 0.8241\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.7033 - val_loss: 0.5602 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.7079 - val_loss: 0.5519 - val_accuracy: 0.8426\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.6963 - val_loss: 0.5454 - val_accuracy: 0.8426\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.6939 - val_loss: 0.5395 - val_accuracy: 0.8426\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6893 - val_loss: 0.5306 - val_accuracy: 0.8519\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.7103 - val_loss: 0.5320 - val_accuracy: 0.7963\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.7103 - val_loss: 0.5286 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6728 - accuracy: 0.6986 - val_loss: 0.5172 - val_accuracy: 0.8056\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7103 - val_loss: 0.5141 - val_accuracy: 0.8056\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7243 - val_loss: 0.5074 - val_accuracy: 0.8056\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6916 - val_loss: 0.5110 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7383 - val_loss: 0.5083 - val_accuracy: 0.8056\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7103 - val_loss: 0.5118 - val_accuracy: 0.8241\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7103 - val_loss: 0.5077 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7033 - val_loss: 0.4983 - val_accuracy: 0.8056\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.7266 - val_loss: 0.4875 - val_accuracy: 0.8148\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6986 - val_loss: 0.4850 - val_accuracy: 0.8148\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7243 - val_loss: 0.4830 - val_accuracy: 0.8148\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7173 - val_loss: 0.4757 - val_accuracy: 0.8241\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7150 - val_loss: 0.4735 - val_accuracy: 0.8148\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7313 - val_loss: 0.4769 - val_accuracy: 0.8241\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7056 - val_loss: 0.4808 - val_accuracy: 0.8241\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7477 - val_loss: 0.4760 - val_accuracy: 0.8241\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6963 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7150 - val_loss: 0.4735 - val_accuracy: 0.8519\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7220 - val_loss: 0.4717 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7220 - val_loss: 0.4661 - val_accuracy: 0.8241\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7547 - val_loss: 0.4638 - val_accuracy: 0.8426\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7360 - val_loss: 0.4521 - val_accuracy: 0.8426\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7009 - val_loss: 0.4527 - val_accuracy: 0.8426\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7383 - val_loss: 0.4546 - val_accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7126 - val_loss: 0.4607 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7383 - val_loss: 0.4538 - val_accuracy: 0.8519\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7079 - val_loss: 0.4503 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7313 - val_loss: 0.4445 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7243 - val_loss: 0.4431 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7383 - val_loss: 0.4282 - val_accuracy: 0.8426\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7453 - val_loss: 0.4208 - val_accuracy: 0.8519\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7266 - val_loss: 0.4175 - val_accuracy: 0.8704\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.7243 - val_loss: 0.4304 - val_accuracy: 0.8519\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7266 - val_loss: 0.4319 - val_accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7220 - val_loss: 0.4449 - val_accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7056 - val_loss: 0.4479 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7453 - val_loss: 0.4414 - val_accuracy: 0.8426\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7009 - val_loss: 0.4290 - val_accuracy: 0.8519\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7220 - val_loss: 0.4282 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7313 - val_loss: 0.4337 - val_accuracy: 0.8426\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7266 - val_loss: 0.4316 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7407 - val_loss: 0.4297 - val_accuracy: 0.8426\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7196 - val_loss: 0.4271 - val_accuracy: 0.8611\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.4348 - val_accuracy: 0.8611\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7103 - val_loss: 0.4337 - val_accuracy: 0.8611\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7243 - val_loss: 0.4286 - val_accuracy: 0.8519\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7360 - val_loss: 0.4246 - val_accuracy: 0.8611\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7407 - val_loss: 0.4202 - val_accuracy: 0.8611\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7430 - val_loss: 0.4214 - val_accuracy: 0.8796\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7336 - val_loss: 0.4256 - val_accuracy: 0.8519\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7196 - val_loss: 0.4182 - val_accuracy: 0.8704\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7266 - val_loss: 0.4233 - val_accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7383 - val_loss: 0.4319 - val_accuracy: 0.8611\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7407 - val_loss: 0.4294 - val_accuracy: 0.8611\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7336 - val_loss: 0.4301 - val_accuracy: 0.8611\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7290 - val_loss: 0.4363 - val_accuracy: 0.8426\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5467 - accuracy: 0.7360 - val_loss: 0.4200 - val_accuracy: 0.8519\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7640 - val_loss: 0.4103 - val_accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7500 - val_loss: 0.4177 - val_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7220 - val_loss: 0.4263 - val_accuracy: 0.8519\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7243 - val_loss: 0.4320 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7313 - val_loss: 0.4282 - val_accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7336 - val_loss: 0.4260 - val_accuracy: 0.8704\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7336 - val_loss: 0.4211 - val_accuracy: 0.8611\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7570 - val_loss: 0.4237 - val_accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7290 - val_loss: 0.4106 - val_accuracy: 0.8704\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7453 - val_loss: 0.4013 - val_accuracy: 0.8704\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7313 - val_loss: 0.4047 - val_accuracy: 0.8611\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7360 - val_loss: 0.4074 - val_accuracy: 0.8519\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7757 - val_loss: 0.4046 - val_accuracy: 0.8611\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8611\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Accuracy score: 0.8611111111111112\n",
      "MSE: 0.1388888888888889\n",
      "R2 score: 0.4444444444444444\n",
      "F1 Score: 0.8605251829530779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86       108\n",
      "         1.0       0.86      0.86      0.86       108\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf \n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Normalisasi data\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# Membuat model Artificial Neural Network (ANN) dengan perubahan\n",
    "model_ann = Sequential([\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=72, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model dengan optimizer RMSprop dan learning rate yang mungkin perlu disesuaikan\n",
    "model_ann.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "finalann = model_ann.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#model_ann.save('diabetes_ANN.h5')\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_ann.evaluate(X_test, y_test)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_prob = model_ann.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "\n",
    "\n",
    "\n",
    "# Pastikan y_test dan y_pred adalah array satu dimensi\n",
    "y_test_single_dim = y_test.ravel()\n",
    "y_pred_single_dim = y_pred_binary.ravel()\n",
    "# Menampilkan classification report\n",
    "print(classification_report(y_test_single_dim, y_pred_single_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_encoded = le.fit_transform(y_test_labels)\n",
    "\n",
    "# Kemudian, gunakan LabelEncoder\n",
    "y_pred_encoded = le.transform(y_pred_labels)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.save_weights('weights_ann_new.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
