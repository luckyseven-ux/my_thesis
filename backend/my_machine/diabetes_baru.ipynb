{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('E:\\\\syntax code\\\\python\\jupytr\\\\neural network\\\\diabetes\\\\diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outcome']\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(  data=df['Age'])\n",
    "plt.title('Bar Chart - Distribusi Umur')\n",
    "plt.xlabel('Umur')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BloodPressure'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_describe=df.describe()\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_describe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4720\\1293082229.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_describe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_describe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pregnancies'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Glucose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BloodPressure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SkinThickness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Insulin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BMI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DiabetesPedigreeFunction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Outcome'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Membuat dokumen Word baru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_describe' is not defined"
     ]
    }
   ],
   "source": [
    "df_describe = pd.DataFrame(data_describe, index=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'])\n",
    "\n",
    "# Membuat dokumen Word baru\n",
    "doc = Document()\n",
    "\n",
    "# Menambahkan tabel ke dalam dokumen Word\n",
    "doc.add_table(rows=len(df_describe) + 1, cols=len(df_describe.columns), style='Table Grid')\n",
    "table = doc.tables[0]\n",
    "\n",
    "# Menambahkan header tabel\n",
    "for col_num, column_name in enumerate(df_describe.columns):\n",
    "    table.cell(0, col_num).text = column_name\n",
    "\n",
    "# Menambahkan data ke dalam tabel\n",
    "for row_num, row_data in enumerate(df_describe.itertuples(index=True, name=None)):\n",
    "    row_cells = table.rows[row_num + 1].cells\n",
    "    for col_num, cell_value in enumerate(row_data[1:]):\n",
    "        row_cells[col_num].text = str(cell_value)\n",
    "\n",
    "# Simpan dokumen Word\n",
    "doc.save('data_describe.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns='Outcome',axis=1)\n",
    "y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 13ms/step - loss: 1.1438 - accuracy: 0.5765 - val_loss: 1.0111 - val_accuracy: 0.6688\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0646 - accuracy: 0.6466 - val_loss: 0.9601 - val_accuracy: 0.6753\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0235 - accuracy: 0.6564 - val_loss: 0.9189 - val_accuracy: 0.6883\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9956 - accuracy: 0.6401 - val_loss: 0.8806 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.9243 - accuracy: 0.6857 - val_loss: 0.8487 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8996 - accuracy: 0.6954 - val_loss: 0.8152 - val_accuracy: 0.7078\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.8426 - accuracy: 0.7166 - val_loss: 0.7873 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.7345 - val_loss: 0.7630 - val_accuracy: 0.7338\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8248 - accuracy: 0.7117 - val_loss: 0.7425 - val_accuracy: 0.7403\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.8322 - accuracy: 0.6873 - val_loss: 0.7310 - val_accuracy: 0.7338\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7851 - accuracy: 0.7231 - val_loss: 0.7157 - val_accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.7166 - val_loss: 0.7026 - val_accuracy: 0.7338\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.7476 - val_loss: 0.6795 - val_accuracy: 0.7338\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.7378 - val_loss: 0.6612 - val_accuracy: 0.7338\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.7134 - val_loss: 0.6510 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.7476 - val_loss: 0.6400 - val_accuracy: 0.7208\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6480 - accuracy: 0.7573 - val_loss: 0.6300 - val_accuracy: 0.7208\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7508 - val_loss: 0.6230 - val_accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7427 - val_loss: 0.6111 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.7622 - val_loss: 0.6044 - val_accuracy: 0.7208\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7622 - val_loss: 0.5998 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.7427 - val_loss: 0.5983 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7720 - val_loss: 0.5906 - val_accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7720 - val_loss: 0.5845 - val_accuracy: 0.7208\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7720 - val_loss: 0.5819 - val_accuracy: 0.7078\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7622 - val_loss: 0.5759 - val_accuracy: 0.7208\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7590 - val_loss: 0.5738 - val_accuracy: 0.7208\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7638 - val_loss: 0.5668 - val_accuracy: 0.7208\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7606 - val_loss: 0.5662 - val_accuracy: 0.7143\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7557 - val_loss: 0.5643 - val_accuracy: 0.7078\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7736 - val_loss: 0.5591 - val_accuracy: 0.7208\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7834 - val_loss: 0.5535 - val_accuracy: 0.7143\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7524 - val_loss: 0.5532 - val_accuracy: 0.7078\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7818 - val_loss: 0.5514 - val_accuracy: 0.7078\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7655 - val_loss: 0.5484 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7143\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7736 - val_loss: 0.5449 - val_accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7687 - val_loss: 0.5424 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7850 - val_loss: 0.5436 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7622 - val_loss: 0.5394 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7769 - val_loss: 0.5373 - val_accuracy: 0.7208\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7704 - val_loss: 0.5352 - val_accuracy: 0.7208\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7524 - val_loss: 0.5356 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7606 - val_loss: 0.5358 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7834 - val_loss: 0.5359 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7524 - val_loss: 0.5341 - val_accuracy: 0.7078\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7736 - val_loss: 0.5324 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7704 - val_loss: 0.5311 - val_accuracy: 0.7208\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7671 - val_loss: 0.5315 - val_accuracy: 0.7208\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7752 - val_loss: 0.5300 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7801 - val_loss: 0.5299 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4996 - accuracy: 0.7687 - val_loss: 0.5286 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7573 - val_loss: 0.5304 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7801 - val_loss: 0.5266 - val_accuracy: 0.7208\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7671 - val_loss: 0.5281 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7655 - val_loss: 0.5256 - val_accuracy: 0.7208\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7606 - val_loss: 0.5252 - val_accuracy: 0.7208\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7915 - val_loss: 0.5263 - val_accuracy: 0.7143\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7818 - val_loss: 0.5259 - val_accuracy: 0.7208\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7687 - val_loss: 0.5236 - val_accuracy: 0.7208\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7866 - val_loss: 0.5264 - val_accuracy: 0.7208\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7899 - val_loss: 0.5255 - val_accuracy: 0.7143\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8143 - val_loss: 0.5234 - val_accuracy: 0.7078\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7818 - val_loss: 0.5212 - val_accuracy: 0.7208\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7687 - val_loss: 0.5220 - val_accuracy: 0.7208\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7785 - val_loss: 0.5221 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7834 - val_loss: 0.5205 - val_accuracy: 0.7143\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7834 - val_loss: 0.5228 - val_accuracy: 0.7143\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7769 - val_loss: 0.5239 - val_accuracy: 0.7143\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7866 - val_loss: 0.5255 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7932 - val_loss: 0.5293 - val_accuracy: 0.7143\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7818 - val_loss: 0.5296 - val_accuracy: 0.7078\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7899 - val_loss: 0.5322 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7883 - val_loss: 0.5264 - val_accuracy: 0.7078\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7801 - val_loss: 0.5236 - val_accuracy: 0.7208\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7850 - val_loss: 0.5281 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8062 - val_loss: 0.5269 - val_accuracy: 0.7208\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7720 - val_loss: 0.5272 - val_accuracy: 0.7208\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7915 - val_loss: 0.5295 - val_accuracy: 0.7208\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7818 - val_loss: 0.5198 - val_accuracy: 0.7208\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7752 - val_loss: 0.5191 - val_accuracy: 0.7208\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7801 - val_loss: 0.5219 - val_accuracy: 0.7208\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.7671 - val_loss: 0.5237 - val_accuracy: 0.7143\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7915 - val_loss: 0.5261 - val_accuracy: 0.7143\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7866 - val_loss: 0.5273 - val_accuracy: 0.7078\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7769 - val_loss: 0.5291 - val_accuracy: 0.7143\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7622 - val_loss: 0.5257 - val_accuracy: 0.7143\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7948 - val_loss: 0.5261 - val_accuracy: 0.7143\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7915 - val_loss: 0.5235 - val_accuracy: 0.7143\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7997 - val_loss: 0.5277 - val_accuracy: 0.7143\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7883 - val_loss: 0.5275 - val_accuracy: 0.7143\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7948 - val_loss: 0.5244 - val_accuracy: 0.7208\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7980 - val_loss: 0.5266 - val_accuracy: 0.7143\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7866 - val_loss: 0.5277 - val_accuracy: 0.7208\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7948 - val_loss: 0.5274 - val_accuracy: 0.7208\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7883 - val_loss: 0.5238 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7834 - val_loss: 0.5227 - val_accuracy: 0.7208\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7866 - val_loss: 0.5279 - val_accuracy: 0.7208\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7932 - val_loss: 0.5255 - val_accuracy: 0.7143\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7866 - val_loss: 0.5247 - val_accuracy: 0.7273\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7273\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Accuracy score: 0.7272727272727273\n",
      "MSE: 0.2727272727272727\n",
      "R2 score: -0.1977777881826639\n",
      "F1 Score: 0.7216083916083916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.73      0.73       154\n",
      "         1.0       0.73      0.73      0.73       154\n",
      "\n",
      "    accuracy                           0.73       308\n",
      "   macro avg       0.73      0.73      0.73       308\n",
      "weighted avg       0.73      0.73      0.73       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf \n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Normalisasi data\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# Membuat model Artificial Neural Network (ANN) dengan perubahan\n",
    "model_ann = Sequential([\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=72, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model dengan optimizer RMSprop dan learning rate yang mungkin perlu disesuaikan\n",
    "model_ann.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "finalann = model_ann.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#model_ann.save('diabetes_ANN.h5')\n",
    "# Evaluasi model\n",
    "loss, accuracy = model_ann.evaluate(X_test, y_test)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_prob = model_ann.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "\n",
    "\n",
    "\n",
    "# Pastikan y_test dan y_pred adalah array satu dimensi\n",
    "y_test_single_dim = y_test.ravel()\n",
    "y_pred_single_dim = y_pred_binary.ravel()\n",
    "# Menampilkan classification report\n",
    "print(classification_report(y_test_single_dim, y_pred_single_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsitektur model dan bobot berhasil disimpan ke file JSON\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Asumsikan Anda memiliki instance model 'model_ann'\n",
    "\n",
    "'''# Serialize arsitektur model ke dalam format JSON\n",
    "model_json = model_ann.to_json()\n",
    "\n",
    "# Simpan arsitektur model ke dalam file\n",
    "with open('model_architecture.json', 'w') as outfile:\n",
    "    outfile.write(model_json)\n",
    "\n",
    "# Serialize bobot model ke dalam format JSON\n",
    "model_weights = model_ann.get_weights()\n",
    "weights_json = [weight.tolist() for weight in model_weights]\n",
    "\n",
    "# Simpan bobot model ke dalam file\n",
    "with open('model_weights.json', 'w') as outfile:\n",
    "    json.dump(weights_json, outfile)'''\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Simpan model ke dalam file H5\n",
    "model_ann.save('model_ANN.h5')\n",
    "print(\"Arsitektur model dan bobot berhasil disimpan ke file JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at E:\\syntax code\\python\\jupytr\\neural network\\diabetes\\diabetes_ANN.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15436\\746453499.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Memuat model yang telah disimpan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:\\\\syntax code\\\\python\\\\jupytr\\\\neural network\\\\diabetes\\\\diabetes_ANN.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Membuat prediksi dengan model yang dimuat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;31m# Legacy case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             raise IOError(\n\u001b[0m\u001b[0;32m    235\u001b[0m                                 \u001b[1;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                             )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at E:\\syntax code\\python\\jupytr\\neural network\\diabetes\\diabetes_ANN.h5"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ...\n",
    "\n",
    "# Memuat model yang telah disimpan\n",
    "loaded_model = load_model('E:\\\\syntax code\\\\python\\\\jupytr\\\\neural network\\\\diabetes\\\\diabetes_ANN.h5')\n",
    "\n",
    "# Membuat prediksi dengan model yang dimuat\n",
    "y_pred_prob_loaded = loaded_model.predict(X_test_scaled)\n",
    "y_pred_loaded = (y_pred_prob_loaded > 0.5).astype(int)\n",
    "\n",
    "# Now you can use y_pred_loaded for evaluation metrics\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "mse_loaded = mean_squared_error(y_test, y_pred_loaded)\n",
    "r2_loaded = r2_score(y_test, y_pred_loaded)\n",
    "f1_loaded = f1_score(y_test, y_pred_loaded, average='weighted')\n",
    "\n",
    "print(\"Accuracy score (loaded model): {}\".format(accuracy_loaded))\n",
    "print(\"MSE (loaded model): {}\".format(mse_loaded))\n",
    "print(\"R2 score (loaded model): {}\".format(r2_loaded))\n",
    "print(\"F1 Score (loaded model): {}\".format(f1_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\n\\nwith open('diabetes_ANN.pkl', 'wb') as file:\\n    pickle.dump(model_ann, file)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "\n",
    "with open('diabetes_ANN.pkl', 'wb') as file:\n",
    "    pickle.dump(model_ann, file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Kemudian, gunakan LabelEncoder\n",
    "y_test_encoded = le.fit_transform(y_test_labels)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_encoded = le.transform(y_pred_labels)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model dari bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classifier\n\u001b[0;32m     15\u001b[0m baru\u001b[38;5;241m=\u001b[39mbuildclassifier()\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mbaru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m baru\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     19\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m baru\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\LUCKY_~1\\AppData\\Local\\Temp\\__autograph_generated_filend7jhohc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def buildclassifier():\n",
    "    classifier = Sequential() #initialize NN\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu', input_dim =X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 24, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform',activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier\n",
    "baru=buildclassifier()\n",
    "history = baru.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "loss, accuracy = baru.evaluate(X_test, y_test)\n",
    "\n",
    "y_pred_prob = baru.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert to one-hot encoded if needed\n",
    "# y_pred_one_hot = to_categorical(y_pred, num_classes=num_classes)\n",
    "\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "print(\"F1 Score: {}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kompleks model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m complex_model \u001b[38;5;241m=\u001b[39m create_complex_model(input_dim)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Melatih model (gantilah X_train, y_train sesuai dengan dataset Anda)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcomplex_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluasi model pada data uji (gantilah X_test, y_test sesuai dengan dataset Anda)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m complex_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\LUCKY_~1\\AppData\\Local\\Temp\\__autograph_generated_filend7jhohc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 2432, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py\", line 5809, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_complex_model(input_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer input\n",
    "    model.add(Dense(units=128, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.1))  # Dropout layer untuk mencegah overfitting\n",
    "    \n",
    "    # Hidden layers\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Mendefinisikan input_dim (sesuai dengan jumlah fitur pada dataset Anda)\n",
    "input_dim = 8  # Sesuaikan dengan jumlah fitur pada dataset diabetes Anda\n",
    "\n",
    "# Membuat model\n",
    "complex_model = create_complex_model(input_dim)\n",
    "\n",
    "# Melatih model (gantilah X_train, y_train sesuai dengan dataset Anda)\n",
    "history = complex_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluasi model pada data uji (gantilah X_test, y_test sesuai dengan dataset Anda)\n",
    "loss, accuracy = complex_model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_pred_prob = complex_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert to one-hot encoded if needed\n",
    "# y_pred_one_hot = to_categorical(y_pred, num_classes=num_classes)\n",
    "\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # You can change the average parameter as needed\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\n\\nwith open('diabetes_kompleks.sav', 'wb') as file:\\n    pickle.dump(complex_model, file)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "\n",
    "with open('diabetes_kompleks.sav', 'wb') as file:\n",
    "    pickle.dump(complex_model, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (154, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 4\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred_encoded \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_pred)\n\u001b[0;32m      6\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test_encoded, y_pred_encoded)\n",
      "File \u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m        Encoded labels.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Lucky_seven\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1204\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (154, 2) instead."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = le.fit_transform(y_test)\n",
    "y_pred_encoded = le.transform(y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "menggunakan model CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 72ms/step - loss: 0.7285 - accuracy: 0.3502 - val_loss: 0.6938 - val_accuracy: 0.3961\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6896 - accuracy: 0.4674 - val_loss: 0.6676 - val_accuracy: 0.6883\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6585 - accuracy: 0.6971 - val_loss: 0.6458 - val_accuracy: 0.7338\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6331 - accuracy: 0.7394 - val_loss: 0.6269 - val_accuracy: 0.7403\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6121 - accuracy: 0.7557 - val_loss: 0.6094 - val_accuracy: 0.7338\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.7557 - val_loss: 0.5939 - val_accuracy: 0.7273\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5644 - accuracy: 0.7687 - val_loss: 0.5800 - val_accuracy: 0.7273\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5461 - accuracy: 0.7541 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5370 - accuracy: 0.7557 - val_loss: 0.5571 - val_accuracy: 0.7338\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5182 - accuracy: 0.7638 - val_loss: 0.5485 - val_accuracy: 0.7468\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5060 - accuracy: 0.7638 - val_loss: 0.5417 - val_accuracy: 0.7662\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4979 - accuracy: 0.7720 - val_loss: 0.5359 - val_accuracy: 0.7792\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4824 - accuracy: 0.7785 - val_loss: 0.5323 - val_accuracy: 0.7857\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4838 - accuracy: 0.7736 - val_loss: 0.5318 - val_accuracy: 0.7857\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4646 - accuracy: 0.7671 - val_loss: 0.5321 - val_accuracy: 0.7857\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4681 - accuracy: 0.7769 - val_loss: 0.5291 - val_accuracy: 0.7792\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4524 - accuracy: 0.7801 - val_loss: 0.5267 - val_accuracy: 0.7792\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4591 - accuracy: 0.7769 - val_loss: 0.5252 - val_accuracy: 0.7792\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4560 - accuracy: 0.7899 - val_loss: 0.5262 - val_accuracy: 0.7792\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.7932 - val_loss: 0.5273 - val_accuracy: 0.7792\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7792\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4349 - accuracy: 0.7964 - val_loss: 0.5316 - val_accuracy: 0.7727\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4362 - accuracy: 0.7948 - val_loss: 0.5347 - val_accuracy: 0.7597\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.7964 - val_loss: 0.5354 - val_accuracy: 0.7597\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4427 - accuracy: 0.7915 - val_loss: 0.5367 - val_accuracy: 0.7597\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4381 - accuracy: 0.7964 - val_loss: 0.5369 - val_accuracy: 0.7597\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4297 - accuracy: 0.7948 - val_loss: 0.5372 - val_accuracy: 0.7597\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4367 - accuracy: 0.7997 - val_loss: 0.5355 - val_accuracy: 0.7727\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4258 - accuracy: 0.8013 - val_loss: 0.5338 - val_accuracy: 0.7727\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4234 - accuracy: 0.8094 - val_loss: 0.5344 - val_accuracy: 0.7727\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4277 - accuracy: 0.8062 - val_loss: 0.5349 - val_accuracy: 0.7792\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4175 - accuracy: 0.7980 - val_loss: 0.5361 - val_accuracy: 0.7792\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4232 - accuracy: 0.8111 - val_loss: 0.5392 - val_accuracy: 0.7727\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4194 - accuracy: 0.8127 - val_loss: 0.5420 - val_accuracy: 0.7727\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.8143 - val_loss: 0.5438 - val_accuracy: 0.7727\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8078 - val_loss: 0.5460 - val_accuracy: 0.7727\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4072 - accuracy: 0.8176 - val_loss: 0.5461 - val_accuracy: 0.7662\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4023 - accuracy: 0.8127 - val_loss: 0.5451 - val_accuracy: 0.7662\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.8143 - val_loss: 0.5444 - val_accuracy: 0.7597\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8013 - val_loss: 0.5449 - val_accuracy: 0.7597\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4035 - accuracy: 0.8176 - val_loss: 0.5468 - val_accuracy: 0.7597\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4201 - accuracy: 0.8029 - val_loss: 0.5477 - val_accuracy: 0.7597\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8111 - val_loss: 0.5476 - val_accuracy: 0.7727\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8192 - val_loss: 0.5478 - val_accuracy: 0.7727\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8046 - val_loss: 0.5462 - val_accuracy: 0.7597\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.8241 - val_loss: 0.5460 - val_accuracy: 0.7532\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5469 - val_accuracy: 0.7532\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4011 - accuracy: 0.8241 - val_loss: 0.5483 - val_accuracy: 0.7597\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3852 - accuracy: 0.8013 - val_loss: 0.5516 - val_accuracy: 0.7532\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3915 - accuracy: 0.8127 - val_loss: 0.5585 - val_accuracy: 0.7532\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3935 - accuracy: 0.8192 - val_loss: 0.5618 - val_accuracy: 0.7468\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.8094 - val_loss: 0.5640 - val_accuracy: 0.7597\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.8094 - val_loss: 0.5638 - val_accuracy: 0.7727\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.8241 - val_loss: 0.5638 - val_accuracy: 0.7403\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3921 - accuracy: 0.8274 - val_loss: 0.5677 - val_accuracy: 0.7403\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.8241 - val_loss: 0.5714 - val_accuracy: 0.7532\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8160 - val_loss: 0.5738 - val_accuracy: 0.7532\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8192 - val_loss: 0.5751 - val_accuracy: 0.7403\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3896 - accuracy: 0.8176 - val_loss: 0.5753 - val_accuracy: 0.7468\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.8306 - val_loss: 0.5743 - val_accuracy: 0.7532\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8176 - val_loss: 0.5728 - val_accuracy: 0.7532\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3877 - accuracy: 0.8306 - val_loss: 0.5737 - val_accuracy: 0.7532\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3772 - accuracy: 0.8143 - val_loss: 0.5760 - val_accuracy: 0.7468\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8355 - val_loss: 0.5802 - val_accuracy: 0.7403\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.8306 - val_loss: 0.5816 - val_accuracy: 0.7338\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3735 - accuracy: 0.8290 - val_loss: 0.5782 - val_accuracy: 0.7468\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3671 - accuracy: 0.8388 - val_loss: 0.5760 - val_accuracy: 0.7532\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.8355 - val_loss: 0.5752 - val_accuracy: 0.7403\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8534 - val_loss: 0.5748 - val_accuracy: 0.7403\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3735 - accuracy: 0.8257 - val_loss: 0.5731 - val_accuracy: 0.7403\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3741 - accuracy: 0.8388 - val_loss: 0.5724 - val_accuracy: 0.7597\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.8502 - val_loss: 0.5739 - val_accuracy: 0.7532\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3670 - accuracy: 0.8469 - val_loss: 0.5800 - val_accuracy: 0.7468\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3720 - accuracy: 0.8420 - val_loss: 0.5896 - val_accuracy: 0.7403\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.8404 - val_loss: 0.5914 - val_accuracy: 0.7597\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3661 - accuracy: 0.8371 - val_loss: 0.5886 - val_accuracy: 0.7468\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3535 - accuracy: 0.8469 - val_loss: 0.5869 - val_accuracy: 0.7532\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3558 - accuracy: 0.8436 - val_loss: 0.5850 - val_accuracy: 0.7532\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3791 - accuracy: 0.8339 - val_loss: 0.5825 - val_accuracy: 0.7532\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3653 - accuracy: 0.8339 - val_loss: 0.5842 - val_accuracy: 0.7468\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.8339 - val_loss: 0.5856 - val_accuracy: 0.7403\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.8371 - val_loss: 0.5872 - val_accuracy: 0.7273\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3610 - accuracy: 0.8388 - val_loss: 0.5892 - val_accuracy: 0.7338\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3539 - accuracy: 0.8420 - val_loss: 0.5884 - val_accuracy: 0.7403\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3548 - accuracy: 0.8436 - val_loss: 0.5921 - val_accuracy: 0.7403\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3669 - accuracy: 0.8404 - val_loss: 0.5995 - val_accuracy: 0.7403\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3459 - accuracy: 0.8306 - val_loss: 0.6062 - val_accuracy: 0.7403\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.8616 - val_loss: 0.6109 - val_accuracy: 0.7468\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3498 - accuracy: 0.8306 - val_loss: 0.6102 - val_accuracy: 0.7468\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3497 - accuracy: 0.8404 - val_loss: 0.6095 - val_accuracy: 0.7403\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3511 - accuracy: 0.8518 - val_loss: 0.6080 - val_accuracy: 0.7532\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3436 - accuracy: 0.8420 - val_loss: 0.6084 - val_accuracy: 0.7532\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3399 - accuracy: 0.8534 - val_loss: 0.6087 - val_accuracy: 0.7468\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3356 - accuracy: 0.8534 - val_loss: 0.6068 - val_accuracy: 0.7403\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.8404 - val_loss: 0.6016 - val_accuracy: 0.7403\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3375 - accuracy: 0.8550 - val_loss: 0.5962 - val_accuracy: 0.7403\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3444 - accuracy: 0.8453 - val_loss: 0.5969 - val_accuracy: 0.7403\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3303 - accuracy: 0.8664 - val_loss: 0.5979 - val_accuracy: 0.7403\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 0.8485 - val_loss: 0.6029 - val_accuracy: 0.7468\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.8567 - val_loss: 0.6061 - val_accuracy: 0.7403\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3332 - accuracy: 0.8518 - val_loss: 0.6101 - val_accuracy: 0.7273\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.8567 - val_loss: 0.6139 - val_accuracy: 0.7403\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3224 - accuracy: 0.8648 - val_loss: 0.6207 - val_accuracy: 0.7273\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3443 - accuracy: 0.8371 - val_loss: 0.6225 - val_accuracy: 0.7338\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3371 - accuracy: 0.8453 - val_loss: 0.6170 - val_accuracy: 0.7273\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3271 - accuracy: 0.8436 - val_loss: 0.6083 - val_accuracy: 0.7273\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3156 - accuracy: 0.8648 - val_loss: 0.6042 - val_accuracy: 0.7403\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3270 - accuracy: 0.8550 - val_loss: 0.6044 - val_accuracy: 0.7597\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3259 - accuracy: 0.8567 - val_loss: 0.6109 - val_accuracy: 0.7468\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 0.8713 - val_loss: 0.6237 - val_accuracy: 0.7338\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3251 - accuracy: 0.8648 - val_loss: 0.6310 - val_accuracy: 0.7338\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3307 - accuracy: 0.8502 - val_loss: 0.6242 - val_accuracy: 0.7403\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.8436 - val_loss: 0.6212 - val_accuracy: 0.7468\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 0.8567 - val_loss: 0.6211 - val_accuracy: 0.7403\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3266 - accuracy: 0.8567 - val_loss: 0.6275 - val_accuracy: 0.7403\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3199 - accuracy: 0.8469 - val_loss: 0.6387 - val_accuracy: 0.7273\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3027 - accuracy: 0.8730 - val_loss: 0.6391 - val_accuracy: 0.7208\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3090 - accuracy: 0.8632 - val_loss: 0.6331 - val_accuracy: 0.7273\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8616 - val_loss: 0.6328 - val_accuracy: 0.7273\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8583 - val_loss: 0.6344 - val_accuracy: 0.7273\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.8534 - val_loss: 0.6414 - val_accuracy: 0.7403\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3136 - accuracy: 0.8664 - val_loss: 0.6532 - val_accuracy: 0.7273\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3114 - accuracy: 0.8664 - val_loss: 0.6496 - val_accuracy: 0.7338\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3055 - accuracy: 0.8697 - val_loss: 0.6491 - val_accuracy: 0.7273\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3168 - accuracy: 0.8453 - val_loss: 0.6516 - val_accuracy: 0.7338\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.8827 - val_loss: 0.6556 - val_accuracy: 0.7338\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3010 - accuracy: 0.8518 - val_loss: 0.6559 - val_accuracy: 0.7403\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2856 - accuracy: 0.8713 - val_loss: 0.6544 - val_accuracy: 0.7403\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 0.8681 - val_loss: 0.6515 - val_accuracy: 0.7468\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2857 - accuracy: 0.8730 - val_loss: 0.6529 - val_accuracy: 0.7468\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2906 - accuracy: 0.8746 - val_loss: 0.6577 - val_accuracy: 0.7468\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.8730 - val_loss: 0.6644 - val_accuracy: 0.7468\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2952 - accuracy: 0.8697 - val_loss: 0.6687 - val_accuracy: 0.7468\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2909 - accuracy: 0.8730 - val_loss: 0.6744 - val_accuracy: 0.7403\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2998 - accuracy: 0.8599 - val_loss: 0.6720 - val_accuracy: 0.7468\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.8681 - val_loss: 0.6718 - val_accuracy: 0.7403\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3032 - accuracy: 0.8681 - val_loss: 0.6757 - val_accuracy: 0.7468\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.8827 - val_loss: 0.6821 - val_accuracy: 0.7208\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2808 - accuracy: 0.8713 - val_loss: 0.6770 - val_accuracy: 0.7208\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2938 - accuracy: 0.8713 - val_loss: 0.6689 - val_accuracy: 0.7468\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2968 - accuracy: 0.8713 - val_loss: 0.6687 - val_accuracy: 0.7468\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2792 - accuracy: 0.8811 - val_loss: 0.6683 - val_accuracy: 0.7532\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.8762 - val_loss: 0.6763 - val_accuracy: 0.7597\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2879 - accuracy: 0.8779 - val_loss: 0.6777 - val_accuracy: 0.7662\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2689 - accuracy: 0.8827 - val_loss: 0.6830 - val_accuracy: 0.7597\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2691 - accuracy: 0.8795 - val_loss: 0.7016 - val_accuracy: 0.7403\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2720 - accuracy: 0.8876 - val_loss: 0.7127 - val_accuracy: 0.7273\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2674 - accuracy: 0.8795 - val_loss: 0.7076 - val_accuracy: 0.7208\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.8713 - val_loss: 0.6952 - val_accuracy: 0.7468\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.8925 - val_loss: 0.6905 - val_accuracy: 0.7468\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2772 - accuracy: 0.8730 - val_loss: 0.6935 - val_accuracy: 0.7143\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2538 - accuracy: 0.8909 - val_loss: 0.6925 - val_accuracy: 0.7208\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2856 - accuracy: 0.8893 - val_loss: 0.6956 - val_accuracy: 0.7403\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2734 - accuracy: 0.8844 - val_loss: 0.6990 - val_accuracy: 0.7273\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2666 - accuracy: 0.8876 - val_loss: 0.7007 - val_accuracy: 0.7273\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2617 - accuracy: 0.8925 - val_loss: 0.7071 - val_accuracy: 0.7143\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2596 - accuracy: 0.8974 - val_loss: 0.7148 - val_accuracy: 0.7078\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2551 - accuracy: 0.8974 - val_loss: 0.7109 - val_accuracy: 0.7208\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2635 - accuracy: 0.8779 - val_loss: 0.7226 - val_accuracy: 0.7208\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2605 - accuracy: 0.8860 - val_loss: 0.7385 - val_accuracy: 0.7143\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2534 - accuracy: 0.8876 - val_loss: 0.7426 - val_accuracy: 0.7078\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2606 - accuracy: 0.8844 - val_loss: 0.7351 - val_accuracy: 0.7208\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2608 - accuracy: 0.8844 - val_loss: 0.7190 - val_accuracy: 0.7273\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 0.9007 - val_loss: 0.7110 - val_accuracy: 0.7338\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.8893 - val_loss: 0.7129 - val_accuracy: 0.7403\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2495 - accuracy: 0.8958 - val_loss: 0.7233 - val_accuracy: 0.7143\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2352 - accuracy: 0.9088 - val_loss: 0.7368 - val_accuracy: 0.7078\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2431 - accuracy: 0.8958 - val_loss: 0.7386 - val_accuracy: 0.7143\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2460 - accuracy: 0.8925 - val_loss: 0.7407 - val_accuracy: 0.7273\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2330 - accuracy: 0.9088 - val_loss: 0.7481 - val_accuracy: 0.7143\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2491 - accuracy: 0.8941 - val_loss: 0.7410 - val_accuracy: 0.7273\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2445 - accuracy: 0.8990 - val_loss: 0.7437 - val_accuracy: 0.7403\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2492 - accuracy: 0.9023 - val_loss: 0.7566 - val_accuracy: 0.7273\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2282 - accuracy: 0.9055 - val_loss: 0.7715 - val_accuracy: 0.7143\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2344 - accuracy: 0.9007 - val_loss: 0.7814 - val_accuracy: 0.7013\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2504 - accuracy: 0.9055 - val_loss: 0.7782 - val_accuracy: 0.7078\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2544 - accuracy: 0.8909 - val_loss: 0.7638 - val_accuracy: 0.7208\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2339 - accuracy: 0.9023 - val_loss: 0.7656 - val_accuracy: 0.7338\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2359 - accuracy: 0.9153 - val_loss: 0.7744 - val_accuracy: 0.7143\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2407 - accuracy: 0.9039 - val_loss: 0.7983 - val_accuracy: 0.7013\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2329 - accuracy: 0.9039 - val_loss: 0.7955 - val_accuracy: 0.7078\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2374 - accuracy: 0.9023 - val_loss: 0.7842 - val_accuracy: 0.7403\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2553 - accuracy: 0.8941 - val_loss: 0.7889 - val_accuracy: 0.7468\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2453 - accuracy: 0.8990 - val_loss: 0.7959 - val_accuracy: 0.7338\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2319 - accuracy: 0.9039 - val_loss: 0.7870 - val_accuracy: 0.7143\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.9039 - val_loss: 0.7810 - val_accuracy: 0.7078\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2285 - accuracy: 0.9121 - val_loss: 0.7825 - val_accuracy: 0.7208\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2428 - accuracy: 0.8909 - val_loss: 0.7866 - val_accuracy: 0.7143\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2198 - accuracy: 0.9023 - val_loss: 0.8001 - val_accuracy: 0.7208\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2321 - accuracy: 0.9169 - val_loss: 0.8263 - val_accuracy: 0.7208\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2276 - accuracy: 0.9023 - val_loss: 0.8422 - val_accuracy: 0.7143\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2479 - accuracy: 0.9055 - val_loss: 0.8260 - val_accuracy: 0.7143\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2181 - accuracy: 0.9153 - val_loss: 0.8110 - val_accuracy: 0.7338\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2108 - accuracy: 0.9169 - val_loss: 0.8048 - val_accuracy: 0.7143\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2086 - accuracy: 0.9251 - val_loss: 0.8140 - val_accuracy: 0.7013\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2196 - accuracy: 0.9088 - val_loss: 0.8159 - val_accuracy: 0.6948\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2150 - accuracy: 0.9104 - val_loss: 0.8203 - val_accuracy: 0.7208\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2158 - accuracy: 0.9283 - val_loss: 0.8369 - val_accuracy: 0.7143\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2251 - accuracy: 0.9055 - val_loss: 0.8455 - val_accuracy: 0.7078\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2205 - accuracy: 0.9088 - val_loss: 0.8495 - val_accuracy: 0.7013\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8495 - accuracy: 0.7013\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "Accuracy score: 0.701298713684082\n",
      "MSE: 0.2987012987012987\n",
      "R2 score: -0.3010101010101014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Confusion Matrix\\nconf_matrix = confusion_matrix(y_test, y_pred)\\n\\n# Classification Report\\nclass_report = classification_report(y_test, y_pred)\\n\\nprint(\"F1 Score: {}\".format(f1))\\nprint(\"\\nConfusion Matrix:\")\\nprint(conf_matrix)\\nprint(\"\\nClassification Report:\")\\nprint(class_report)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat model Neural Network\n",
    "model_nn = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Kompilasi model\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model_nn.fit(X_train, y_train, epochs=200, batch_size=256, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model_nn.evaluate(X_test, y_test)\n",
    "model_nn.save('diabetes_CNN.h5')\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_pred_prob = model_nn.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert to one-hot encoded if needed\n",
    "# y_pred_one_hot = to_categorical(y_pred, num_classes=num_classes)\n",
    "\n",
    "# Now you can use y_pred for evaluation metrics\n",
    "print(\"Accuracy score: {}\".format(accuracy))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2 score: {}\".format(r2_score(y_test, y_pred)))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # You can change the average parameter as needed\n",
    "'''\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "\n",
    "with open('diabetes_CNN.sav', 'wb') as file:\n",
    "    pickle.dump(model_nn, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "le = LabelEncoder()\n",
    "y_test_encoded = le.fit_transform(y_test)\n",
    "y_pred_encoded = le.transform(y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 44ms/step - loss: 0.6893 - accuracy: 0.5619 - val_loss: 0.6767 - val_accuracy: 0.6299\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.6531 - val_loss: 0.6591 - val_accuracy: 0.6948\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7134 - val_loss: 0.6425 - val_accuracy: 0.6948\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.7215 - val_loss: 0.6272 - val_accuracy: 0.7013\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6184 - accuracy: 0.7231 - val_loss: 0.6121 - val_accuracy: 0.7143\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6024 - accuracy: 0.7280 - val_loss: 0.5983 - val_accuracy: 0.7078\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5869 - accuracy: 0.7345 - val_loss: 0.5854 - val_accuracy: 0.7078\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7345 - val_loss: 0.5731 - val_accuracy: 0.7078\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.7345 - val_loss: 0.5622 - val_accuracy: 0.7013\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7394 - val_loss: 0.5524 - val_accuracy: 0.7208\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5602 - accuracy: 0.7078\n",
      "Test Loss: 1.5602\n",
      "Test Accuracy: 0.7078\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca dataset\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Membagi dataset menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengubah dimensi data untuk LSTM\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Membuat model LSTM dengan optimizator Adam\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Kompilasi model dengan optimizator Adam\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model_lstm.fit(X_train_lstm, y_train, epochs=10, batch_size=64, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "loss, accuracy = complex_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
